########
# Copyright (c) 2017-2018 MSO4SC - javier.carnero@atos.net
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tosca_definitions_version: cloudify_dsl_1_3

imports:
    # to speed things up, it is possible downloading this file,
    - http://raw.githubusercontent.com/mso4sc/cloudify-hpc-plugin/master/resources/types/cfy_types.yaml
    - https://raw.githubusercontent.com/MSO4SC/cloudify-im-extension/master/im.yaml
    # relative import of plugin.yaml that resides in the blueprint directory
    - plugin.yaml
    - inputs_def.yaml

inputs:
  singularity_image_uri_opm:
    description: URI pointing to the singularity image
    default: "shub://sregistry.srv.cesga.es/mso4sc/opm-release:latest"
  
  hpc_reservation:
    description: Computing reservation to use on the HPC system chosen
    default: ""
  
  parallel_tasks:
    description: number of tasks/processes to run in parallel
    default: 1

  parallel_nodes:
    description: number of nodes on which to run
    default: 1

  parallel_tasks_per_node:
    description: number of tasks/processes to run in parallel
    default: 1

  max_time:
    description: maximum allowed time for run (minutes and seconds)
    default: '00:30:00'

dsl_definitions:
- &singularity_image_filename
  "mso4sc-opm-image.simg"

node_templates:
  hpc_wm:
    type: hpc.nodes.WorkloadManager
    properties:
      config: { get_input: hpc_wm_config }
      credentials: { get_input: hpc_wm_credentials }
      external_monitor_entrypoint: { get_input: monitor_entrypoint }
      job_prefix: { get_input: job_prefix }
      base_dir: { get_input: hpc_base_dir }
      monitor_period: 15
      skip_cleanup: true
      workdir_prefix: "single_singularity"
      simulate: True # Comment to test with real infrastructure
      
  im_wm:
    type: hpc.nodes.WorkloadManager
    properties:
      config: { get_input: secondary_cloud_wm_config }
      credentials: { get_input: secondary_cloud_wm_credentials }
      external_monitor_entrypoint: { get_input: monitor_entrypoint }
      job_prefix: { get_input: job_prefix }
      workdir_prefix: "single_eosc"
      skip_cleanup: True
      simulate: True # Comment to test with real infrastructure
    relationships:
    - type: wm_contained_in
      target: vitual_machine

  opm_flow_single_job:
    type: hpc.nodes.SingularityJob
    properties:
      job_options:
        pre:
        - { get_input: mpi_load_command }
        - { get_input: singularity_load_command }
        - 'singularity run -B /mnt remotelogger-cli.simg -f logfilter.yaml -sh logging.mso4sc.eu -u mso4sc -p remotelogger -e test -rk $CFY_EXECUTION_ID -q $CFY_JOB_NAME &> remotelogger.log & echo Logger $CFY_EXECUTION_ID @ CFY_JOB_NAME Launched'
        partition: { get_input: partition_name }
        reservation: { get_input: hpc_reservation }
        image: { concat: [ '$CURRENT_WORKDIR/', *singularity_image_filename ] }
        volumes:
        - { get_input: scratch_voulume_mount_point }
        - { get_input: singularity_mount_point }
        command: 'flow $CURRENT_WORKDIR/run_generated.param output_dir=$CURRENT_WORKDIR/simoutput'
        nodes: { get_input: parallel_nodes }
        tasks: { get_input: parallel_tasks }
        tasks_per_node: { get_input: parallel_tasks_per_node }
        max_time: { get_input: max_time }
        post:
        - 'tar czvf output.tgz $CURRENT_WORKDIR/simoutput '
      deployment:
        bootstrap: 'scripts/singularity_bootstrap_run-flow-generic.sh'
        revert: 'scripts/singularity_revert_run-flow-generic.sh'
        inputs:
        - { get_input: input_url }
        - { get_input: singularity_image_uri_opm }
        - *singularity_image_filename
      skip_cleanup: True
    relationships:
    - type: job_managed_by_wm
      target: hpc_wm

  vm_job:
    type: hpc.nodes.Job
    properties:
      job_options:
        type: 'SHELL'
        command: 'touch processed_sim.out'
      skip_cleanup: True
      publish:
      - dataset: { get_input: ckan_outputs_dataset }
        file_path: "$CURRENT_WORKDIR/processed_sim.out"
        name: "processed_outputs"
        description: "Processed outputs"
    relationships:
      - type: job_managed_by_wm
        target: im_wm
      - type: job_depends_on
        target: opm_flow_single_job
      
      
  ########### IM extension ##########
  vitual_machine:
    type: im.nodes.Server
    properties:
      config: { get_input: eosc_config }
      resource_id: vm_test
      simulate: True # Comment to test with real infrastructure
    relationships:
    - type: depends_on_setting
      target: network
    - type: depends_on_setting
      target: image
    - type: depends_on_setting
      target: flavour
    - type: depends_on_setting
      target: software

  network:
    type: im.nodes.Network
    properties:
      name: net
      config: { get_input: secondary_cloud_network_config }
      use_external_resource: true
      resource_id: { get_input: secondary_cloud_network_id }
      simulate: True # Comment to test with real infrastructure

  image:
    type: im.nodes.Image
    properties:
      name: { get_input: secondary_cloud_image_name }
      config: 
        id: { get_input: secondary_cloud_image_id }
        storage: { get_input: secondary_cloud_flavor_memory }
        username: { get_input: secondary_cloud_image_user }
        password: { get_input: secondary_cloud_image_pass }
        public_key: { get_input: secondary_cloud_image_public }
        private_key: { get_input: secondary_cloud_image_private }
      use_external_resource: true
      resource_id: default_image
      simulate: True # Comment to test with real infrastructure

  flavour:
    type: im.nodes.Flavour
    properties:
      name: { get_input: secondary_cloud_flavor_name }
      config: { get_input: secondary_cloud_flavor_config }
      use_external_resource: true
      resource_id: { get_input: secondary_cloud_flavor_id }
      simulate: True # Comment to test with real infrastructure

  software:
    type: im.nodes.Software
    properties:
      name: singularity-openmpi
      config: 
        packages: ["openmpi", "singularity"]
        deploy: |
          ln -s /usr/lib64/openmpi/bin/mpirun /usr/bin/mpirun
      use_external_resource: true
      resource_id: default_software
      simulate: True # Comment to test with real infrastructure

outputs:
  single_job_name:
    description: single job name in the VM
    value: { get_attribute: [vm_job, job_name] }
