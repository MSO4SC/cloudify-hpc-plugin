########
# Copyright (c) 2017-2018 MSO4SC - javier.carnero@atos.net
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tosca_definitions_version: cloudify_dsl_1_3

imports:
    # to speed things up, it is possible downloading this file,
    - http://raw.githubusercontent.com/mso4sc/cloudify-hpc-plugin/master/resources/types/cfy_types.yaml
    - http://www.getcloudify.org/spec/openstack-plugin/2.9.0/plugin.yaml
    # relative import of plugin.yaml that resides in the blueprint directory
    - plugin.yaml

inputs:
    monitor_entrypoint:
        description: Monitor entrypoint IP
        default: ""
        type: string

    job_prefix:
        description: Job name prefix in HPCs
        default: "cfyhpc"
        type: string

    mso4sc_wm_hpc:
        description: Configuration of the workload manager for the  HPC to be used
        default: {}

    partition:
        description: Partition in which the jobs will run
        default: "public"
        type: string

    mso4sc_wm_openstack:
        description: Configuration of the workload manager for the VM to be used
        default: {}

    ################### DATA PUBLISH ##################
    mso4sc_datacatalogue_entrypoint:
        description: entrypoint of the data catalogue
        default: "http://193.144.35.207"

    mso4sc_datacatalogue_key:
        description: API Key to publish the outputs
        default: ""

    mso4sc_outdataset_outputs_at:
        description: ID of the CKAN output dataset
        default: ""

    #################### OPENSTACK ####################
    openstack_config:
        default: {}

    openstack_network:
        default: ""

    openstack_keypair:
        default: ""

    openstack_floatingip:
        default: ""
    
    openstack_image:
        default: ""
    
    openstack_flavor:
        default: ""

    ###################################################

node_templates:
    hpc_wm:
        type: hpc.nodes.WorkloadManager
        properties:
            config: { get_input: mso4sc_wm_hpc }
            external_monitor_entrypoint: { get_input: monitor_entrypoint }
            job_prefix: { get_input: job_prefix }
            base_dir: "$LUSTRE"
            workdir_prefix: "four_scale"
            monitor_period: 15
            skip_cleanup: True
            simulate: True  # COMMENT to test against a real HPC
    
    first_job:
        type: hpc.nodes.Job
        properties:
            job_options:
                type: 'SBATCH'
                command: "touch.script fourth_example_1.test"
                scale: 4
            deployment:
                bootstrap: 'scripts/bootstrap_sbatch_example.sh'
                revert: 'scripts/revert_sbatch_example.sh'
                inputs:
                    - 'first_job'
                    - { get_input: partition }
            skip_cleanup: True
        relationships:
            - type: job_managed_by_wm
              target: hpc_wm

    second_parallel_job:
        type: hpc.nodes.SingularityJob
        properties:
            job_options:
                modules:
                    - gcc/5.3.0
                    - openmpi/1.10.2
                    - singularity/2.3.1
                partition: { get_input: partition }
                image: '$LUSTRE/openmpi_1.10.7_ring.img'
                home: '$HOME:/home/$USER'
                volumes:
                    - '/scratch'
                command: 'ring > fourth_example_2.test'
                nodes: 1
                tasks: 1
                tasks_per_node: 1
                max_time: '00:01:00'
                scale: 2
            deployment:
                bootstrap: 'scripts/singularity_bootstrap_example.sh'
                revert: 'scripts/singularity_revert_example.sh'
                inputs:
                    - '$LUSTRE'
                    - 'openmpi_1.10.7_ring.img'
            skip_cleanup: True
        relationships:
            - type: job_managed_by_wm
              target: hpc_wm
            - type: job_depends_on
              target: first_job
    
    third_parallel_job:
        type: hpc.nodes.SingularityJob
        properties:
            job_options:
                modules:
                    - gcc/5.3.0
                    - openmpi/1.10.2
                    - singularity/2.3.1
                partition: { get_input: partition }
                image: '$LUSTRE/openmpi_1.10.7_ring.img'
                home: '$HOME:/home/$USER'
                volumes:
                    - '/scratch'
                command: 'ring > fourth_example_3.test'
                nodes: 1
                tasks: 1
                tasks_per_node: 1
                max_time: '00:01:00'
                scale: 2
            deployment:
                bootstrap: 'scripts/singularity_bootstrap_example.sh'
                revert: 'scripts/singularity_revert_example.sh'
                inputs:
                    - '$LUSTRE'
                    - 'openmpi_1.10.7_ring.img'
            skip_cleanup: True
        relationships:
            - type: job_managed_by_wm
              target: hpc_wm
            - type: job_depends_on
              target: first_job

    fourth_job:
        type: hpc.nodes.Job
        properties:
            job_options:
                type: 'SBATCH'
                command: "touch.script fourth_example_4.test"
                scale: 4
            deployment:
                bootstrap: 'scripts/bootstrap_sbatch_example.sh'
                revert: 'scripts/revert_sbatch_example.sh'
                inputs:
                    - 'fourth_job'
                    - { get_input: partition }
            skip_cleanup: True
        relationships:
            - type: job_managed_by_wm
              target: hpc_wm
            - type: job_depends_on
              target: second_parallel_job
            - type: job_depends_on
              target: third_parallel_job

outputs:
    first_job_name:
        description: first job name
        value: { get_attribute: [first_job, job_name] }
    second_job_name:
        description: second job name
        value: { get_attribute: [second_parallel_job, job_name] }
    third_job_name:
        description: third job name
        value: { get_attribute: [third_parallel_job, job_name] }
    fourth_job_name:
        description: fourth job name
        value: { get_attribute: [fourth_job, job_name] }
